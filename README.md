# Hype /brdev scrapper: An√°lise de Popularidade de Tecnologias

Este projeto realiza web scraping focado no subreddit `r/brdev` e na busca do GitHub para analisar a popularidade e a atividade de diversas tecnologias de programa√ß√£o. O objetivo √© comparar o "hype" (men√ß√µes na comunidade) com a "realidade" (n√∫mero de projetos ativos), gerando insights para desenvolvedores.

Este trabalho foi desenvolvido para a disciplina INE5454 - T√≥picos Avan√ßados em Ger√™ncia de Dados.

## üöÄ Funcionalidades

- Scraping de posts e coment√°rios do subreddit `r/brdev`.
- Coleta de m√©tricas de reposit√≥rios do GitHub de forma otimizada para evitar bloqueios por taxa de uso.
- Gera√ß√£o de um dataset final em formato JSON com mais de 1000 inst√¢ncias.
- An√°lise dos dados e cria√ß√£o de gr√°ficos para visualiza√ß√£o dos resultados.

## üõ†Ô∏è Pr√©-requisitos

Antes de come√ßar, garanta que voc√™ tem os seguintes softwares instalados:

- [Python](https://www.python.org/downloads/) (vers√£o 3.10 ou superior)
- [Poetry](https://python-poetry.org/docs/#installation) (gerenciador de depend√™ncias)

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

Siga os passos abaixo para configurar o ambiente do projeto:

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Instale as depend√™ncias:**
    O Poetry ir√° ler o arquivo `pyproject.toml`, criar um ambiente virtual e instalar todas as bibliotecas necess√°rias (`requests`, `beautifulsoup4`, `pandas`, `matplotlib`, `seaborn`, etc.).
    ```bash
    poetry install
    ```

## ‚ñ∂Ô∏è Como Executar

A execu√ß√£o √© dividida em duas etapas principais, mas o scraper principal j√° est√° configurado para rodar tudo o que √© preciso para a coleta.

### Passo 1: Coletar os Dados

Este comando executa o scraper principal. Ele primeiro varre o Reddit e depois o GitHub. **Este processo √© longo e pode levar de 30 a 40 minutos**, dependendo da sua conex√£o.

```bash
poetry run python src/scraper.py
```

Ao final, ele criar√° o arquivo `dataset_completo.json` na raiz do projeto.

### Passo 2: Analisar os Dados e Gerar os Gr√°ficos

Ap√≥s a coleta, execute este script para ler o `dataset_completo.json`, analisar os dados e gerar os quatro gr√°ficos de visualiza√ß√£o.

```bash
poetry run python src/analise.py
```

## üìä Arquivos Gerados

Ap√≥s a execu√ß√£o dos scripts, os seguintes arquivos ser√£o criados:

- `dataset_completo.json`: O dataset final com todas as men√ß√µes coletadas e enriquecidas com os dados do GitHub.
- `grafico_1_hype_reddit.png`: Gr√°fico com o ranking de tecnologias por men√ß√µes no `r/brdev`.
- `grafico_2_atividade_github.png`: Gr√°fico com o ranking de tecnologias por reposit√≥rios ativos no GitHub.
- `grafico_3_tendencia_temporal.png`: Gr√°fico de linhas mostrando a tend√™ncia de men√ß√µes das Top 5 tecnologias.
- `grafico_4_ratio_hype.png`: Gr√°fico comparativo da propor√ß√£o Hype vs. Atividade.
